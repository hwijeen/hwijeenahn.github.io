---
layout: post
title: "데이터 사이언티스트 인터뷰 질문 및 답변 1"
description: ""
comments: true
categories: [ML/수학/통계]
tags:
- Interview Question
---



## Machine Learning

#### <U>1. Cross-validation이 무엇인가요? 어떻게 하나요?</U>

통계적 분석의 결과가 얼마나 일반화 가능한지 평가하는 모델 테스트 방법. 단일 테스트 데이터 set을 사용할 경우, 모형의 성능 평가는 이 테스트 데이터에만 의존. 여러 테스트 셋에 대해 반복적으로 성능 평가함으로써 미지의 데이터에 대해서 얼마나 좋은 성능을 낼지 평가한다. 

LOOCV의 경우 거의 모든 data를 train에 사용하므로 측정된 test error는 low bias. 그러나 n개의 test error가 서로 높은 상관을(다 비슷) 가지므로, 이들을 평균낸 최종 error는 high variance.

* TODO : How to do CV right      

<br>

#### <U>2. 회귀 / 분류시 알맞은 Metric은?</U>

Regression이냐 Classification이냐에 따라, *Business goal*에 따라, *target variable의 분포*에 따라 고른다. 우리가 optimize하는 대상이 되기 때문에 신중히 고를 필요가 있다.

Regression의 경우 MSE(Mean Squared Error), MAE(Mean Absolute Error)는 **큰 에러가 높은 가중치**를 갖게끔 되어있다. 큰 Error에 대해서 페널티를 많이 주고 싶다면 MSE가 적절하다. MAE는 linear score로, **outlier에 more robust**하다.


$$
\\
MSE = \sqrt{\frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2}		\\
MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i-\hat{y}_i|			\\
$$


이 외에 RMSLE(Root Mean Squared Logarithmic Error), WMAE(Weighted Mean Absolute Error)가 있다. RMLSE의 경우 **over estimated value를 under estimate보다 더 크게 penalize** 하는 특징이 있다 (RMSE는 under, over에 동일). 최근 / 과거 데이터에 대해 다른 가중치를 써야하는 추천시스템 경우, WMAE를 고려해볼 수 있다.

<p style="text-align:center;"><img src="/assets/img/RMSLE.png" width="500" alt="RMSLE" align="middle"></p>

Classification의 metric은 기본적으로 Accuracy, Recall, Precision가 있다. Accuracy paradox는 unbalanced classes 경우 찍는 것도 accuracy가 높다는 얘기. Precision은 내 분류가 얼마냐 정확하냐, 즉 맞다고 한 것중에 얼마나 맞았냐. Recall은 실제 정답 중에 내가 몇 개나 맞췄나 리뷰하는 느낌. 

위에 3개의 metric은 모두 unbalanced classe에 민감하다는 특징이 있다. F1 Score은 Precision과 Recall의 *조화평균*으로, target variable이 unbalanced일 때 사용한다. ROC는 binary classifier의 성능을 그래프로 표현해주며, unbalanced classes에 민감하지 않다.

- TODO : F1 Score 의미, ROC     


   <br>

#### <U>3. 정규화(regularization)이 뭐고 왜 유용한가요? ridge와 lasso의 장단점이 뭔가요?</U>

Train data에 오버피팅되는 것을 방지함으로써 **모델의 일반화 정도(generalization)을 높이는 방법**이다. Loss function(minimization problem)에 regularization term을 추가함으로써 모델의 complexity를 낮출 수 있다. "같은 현상을 설명하는 두 개의 주장이 있다면 간단한 쪽을 선택해라"라는 **Occam's razor**원리를 따르는 개념이라고 할 수 있다.

Ridge regression은 loss function에 **L2 penalty**를 추가한다. hyperparameter $$\lambda $$를 통해서 bias-variance tradeoff 정도를 조정할 수 있다. **lasso 보다 조금 빠르다는 특징이 있다**

Lasso는 **L1 penalty**를 부여한다. 중요한 몇 개의 변수((회귀의 계수로 이해)만 선택하고 나머지는 가 0이 되게하는 효과가 있어서, 그 자체로 **feature selection method**로 자주 쓰인다.

Ridge, lasso term을 추가한 회귀식을 ridge regresssion, lasso regression이라고 한다.

* [참고](https://brunch.co.kr/@itschloe1/11)  


<br>

#### <U>4. Local optimum이 뭔가요? K-means clustering같이 특정 알고리즘에서 local optimum문제가 중요한 이유가 뭔가요? <U>

**주변** candidate solution 중에서 optimal한 게 local optimum. Global optimum은 **모든** candidate solution중 최적의 solution을 말한다. 

K-means 알고리즘은 local optimum을 찾을 때까지 cost function을 줄여가는 방향으로 작동한다. 처음에 random assignment를 어떻게 하냐에 따라 다른 local optimum에 도착할 수 있다. 다른 초기화에 따라 다른 답이 나오는 결과를 보고 local optimum에 빠졌음을 알 수 있다. 또한, local optimum에 빠지는 많은 경우 수렴이 빠르다는 특징이 있다.

K-means의 경우 여러 가지 초기화로 알고리즘을 돌리고, lowest cost를 갖는 초기화 방법을 택할 필요가 있다!

<br>

#### <U>5. 왜 dot product가 두 벡터의 유사도를 측정하는 데 쓰이나요?</U>

대표적 similarity metric으로 cosine similarity가 있다.


$$
cosine(\theta) = \frac{\mathbf{x \cdot y}}{||x|| \cdot ||y||}
$$

두 벡터 x, y를 먼저 normalize시켜주면 cosine similarity는 정규화된 두 벡터의 내적으로 생각할 수 있다.

정규화 시켜준다는 것의 의미 벡터의 크기는 고려하지 않고 방향성분만 고려한다는 걸 의미한다. 어떤 문서를 BOW방식을 통해 vector로 표현하는 상황을 고려해보자. 두 문서 D1, D2가 같은 내용을 다루더라도(쓰이는 단어가 같더라도) 만약 두 문서의 길이가 현저하게 차이 난다면 두 문서의 벡터 또한 크기 차이가 나게 된다. 이 때 두 벡터를 정규화를 해주고 내적을 하면(cosine similarity) 두 문서는 비슷하게(값이 크다) 나오니까, 직관에 맞는 distance metric으로 쓸 수 있다.

- TODO : NLP할 때 보통 정규화 해주나...? pretrained vector들은 정규화 된 애들인가..?

- [참고](https://nlp.stanford.edu/IR-book/html/htmledition/dot-products-1.html)

  

