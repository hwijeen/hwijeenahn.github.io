---
layout: post
title: "Meta learning Syllabus"
description: ""
comments: true
categories: []
tags:
- Meta learning
- Syllabus
typora-root-url: ../../hwijeen.github.io
---

## Motivation

![Screen Shot 2020-11-02 at 11.22.16](/assets/img/Screen Shot 2020-11-02 at 11.22.16.png)

An evaluation of supervised learning model assumes static distribution of data. In reality, it is often the case that the data distributino is constantly changing. In this scenario, meta-learning is to rescue.

## Problem Setting

![Screen Shot 2020-11-02 at 14.10.15](/assets/img/meta_learning_prob_set.png)

Multi-task learning and transfer learning differs in terms of whether target task is present at the training time. 

![Screen Shot 2020-11-02 at 14.14.07](/assets/img/view_on_meta_learning.png)

## Case Study: GPT-3

![Screen Shot 2020-11-02 at 14.42.50](/assets/img/Screen Shot 2020-11-02 at 14.42.50.png)

![Screen Shot 2020-11-02 at 14.43.20](/assets/img/Screen Shot 2020-11-02 at 14.43.20.png)

## References

[Chelsea Finn's CS330](http://cs330.stanford.edu)

[Lilian Weng's blog post](https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html)



