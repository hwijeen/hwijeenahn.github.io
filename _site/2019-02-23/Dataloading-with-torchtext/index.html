<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Dataloading with torchtext</title>

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/main.css" type="text/css">
  <!-- Font -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <link href='//spoqa.github.io/spoqa-han-sans/css/SpoqaHanSans-kr.css' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Ubuntu+Mono" rel="stylesheet">
  <link rel="alternate" type="application/rss+xml" title="RSS Feed for Hwijeen Ahn" href="/feed.xml" />
  <!-- Begin Jekyll SEO tag v2.4.0 -->
<title>Dataloading with torchtext | Hwijeen Ahn</title>
<meta name="generator" content="Jekyll v3.8.0" />
<meta property="og:title" content="Dataloading with torchtext" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Torchtext 사용하기 - template과 설명" />
<meta property="og:description" content="Torchtext 사용하기 - template과 설명" />
<link rel="canonical" href="http://localhost:4000/2019-02-23/Dataloading-with-torchtext/" />
<meta property="og:url" content="http://localhost:4000/2019-02-23/Dataloading-with-torchtext/" />
<meta property="og:site_name" content="Hwijeen Ahn" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-02-23T00:00:00+09:00" />
<script type="application/ld+json">
{"headline":"Dataloading with torchtext","dateModified":"2019-02-23T00:00:00+09:00","datePublished":"2019-02-23T00:00:00+09:00","description":"Torchtext 사용하기 - template과 설명","url":"http://localhost:4000/2019-02-23/Dataloading-with-torchtext/","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2019-02-23/Dataloading-with-torchtext/"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


  <!-- Icons -->
  <!-- 16x16 -->
  <link rel="shortcut icon" href="http://localhost:4000/logo.png">
  <!-- 32x32 -->
  <link rel="shortcut icon" href="http://localhost:4000/logo.png">

  <!-- Google Analytics -->

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-112068488-2', 'auto');
ga('send', 'pageview');

</script>



</head>

<body>
  <div class="content-container">
    


<header>
  <div class="header-small">
    <a href="http://localhost:4000">Hwijeen Ahn</a>
  </div>
</header>
<div class="post">
  <div class="post-title">Dataloading with torchtext</div>
  <span class="post-date">
    <time>23 Feb 2019</time>
  </span>

  
    <span class="post-minute"> 
     3 minute read
    </span>
  


  <div class="post-tag">
    <ul>
      
      <li>
        <a href="http://localhost:4000/tags#torchtext">
          <span>torchtext</span>
        </a>
      </li>
      
      
    </ul>
  </div>

  <p>Torchtext는 ‘파일 읽어오기 - tokenization - dataset split - build vocabulary -  numericalization - pretrained word embedding - batch iterator’ 일련의 과정을 편리하게 할 수 있도록 도와준다. Supervised learning할 때 torchtext를 사용하는 방법과 그 설명을 정리했다 <a href="http://anie.me/On-Torchtext/">외국 블로그</a>글, torchtext 소스코드를 참고했다.</p>

<h2 id="torchtextdatafield">torchtext.data.Field</h2>

<p><code class="highlighter-rouge">Field</code>는 data의 한 영역을 represent하는 데 쓰인다. Supervised learning을 위한 paired data의 경우 src문장과 trg문장이 하나의 파일에 저장되어 있는 경우가 많다. 이때,  tab등의 구분자로 나뉘는 각 열에 해당하는 게 <code class="highlighter-rouge">Field</code>이다. <code class="highlighter-rouge">Field</code>를 만들 때 인자로 넘기는 것들은 그 필드에 적용할 전/후처리 등에 대한 정보이다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">MAXLEN</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">SRC</span> <span class="o">=</span> <span class="n">ReversibleField</span><span class="p">(</span><span class="n">tokenize</span><span class="o">=</span><span class="s">'spacy'</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">include_lengths</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                          <span class="n">preprocessing</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[:</span><span class="n">MAXLEN</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span>
<span class="n">TGT</span> <span class="o">=</span> <span class="n">ReversibleField</span><span class="p">(</span><span class="n">tokenize</span><span class="o">=</span><span class="s">'spacy'</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">include_lengths</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                          <span class="n">preprocessing</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[:</span><span class="n">MAXLEN</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span>
</code></pre></div></div>

<p><code class="highlighter-rouge">Include_lengths</code>와 <code class="highlighter-rouge">batch_first</code>는 <code class="highlighter-rouge">Iterator</code>가 batch tensor을 내뱉을 때 영향을 미치지만, 여기서부터 설정해줘야한다. Pytorch의 <code class="highlighter-rouge">pack_padded_sequence</code>는 인자로 paddding된 batch와 batch내 example들의 길이 정보를 받기 때문에 <code class="highlighter-rouge">include_lengths=True</code>가 필요하다. <code class="highlighter-rouge">batch_first</code>는 선택사항이다. 텍스트 데이터를 다룰 때 최대 길이 설정도 사실상 필수인데, 여기서 lambda function을 통해 최대 길이를 넘는 부분은 잘라버린다. 이후 lambda function의 input으로 들어가는 x는 <code class="highlighter-rouge">Example</code>(=list of strings)이다.</p>

<ul>
  <li>Spacy tokenizer 사용시 다른 기능은 load하지 않는 방법은 <a href="https://spacy.io/usage/processing-pipelines#disabling">여기</a></li>
</ul>

<h2 id="torchtextdatadataset">torchtext.data.Dataset</h2>

<p><code class="highlighter-rouge">Dataset</code>는 <code class="highlighter-rouge">Example</code> 단위로 정리된 데이터들을 갖는 클래스이다. 많은 경우에 로컬에 특정 형태로 저장된 데이터를 사용할텐데, 이 경우 사용해야하는 class는 <code class="highlighter-rouge">TabularDataset</code>이다. Instance를 만든 뒤엔 인덱싱을 통한 <code class="highlighter-rouge">Example</code> 접근(__getitem__), <code class="highlighter-rouge">len</code> 메서드 사용(__len__), <code class="highlighter-rouge">Example</code>에 대한 iteration(__iter__), <code class="highlighter-rouge">Example</code>들의 특정 Field에 대한 iteration(__getattr__)을 지원한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">corpus</span> <span class="o">=</span> <span class="n">TabularDataset</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s">'./data/en-fr.toy.txt'</span><span class="p">,</span> <span class="n">format</span><span class="o">=</span><span class="s">'tsv'</span><span class="p">,</span>
                            <span class="n">fields</span><span class="o">=</span><span class="p">[(</span><span class="s">'src'</span><span class="p">,</span> <span class="n">SRC</span><span class="p">),</span> <span class="p">(</span><span class="s">'tgt'</span><span class="p">,</span> <span class="n">TGT</span><span class="p">)])</span>
<span class="n">train</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">corpus</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">split_ratio</span><span class="o">=</span><span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])</span> 
</code></pre></div></div>

<p><code class="highlighter-rouge">TabularDataset</code>이 <code class="highlighter-rouge">Example</code>을 만들려면 데이터가 어떻게 생겼는지에 대한 정보, 즉 <code class="highlighter-rouge">Field</code> 정보가 필요하기에 instance를 만들 때 <code class="highlighter-rouge">Field</code>를 dictionary혹은 list of tuples로 넘겨줘야한다. <code class="highlighter-rouge">TabularDataset</code> instance를 train, valid, test로 나누는 건 <code class="highlighter-rouge">.split()</code>라는 instance method를 이용한다. 만약 로컬에 있는 파일이 이미 split된 상태라면, <code class="highlighter-rouge">.splits()</code>라는 class method를 통해 각각 읽어올 수 있다.</p>

<ul>
  <li><a href="https://github.com/pytorch/text/issues/375">두 Dataset을 병합하는 방법</a>. 만약 데이터가 label 별로 다른 파일에 저장되어 있을 때 유용하다.</li>
</ul>

<h2 id="torchtextdatafieldbuild_vocab">torchtext.data.Field.build_vocab()</h2>

<p>Torchtext에서 <code class="highlighter-rouge">Vocab</code>은 <code class="highlighter-rouge">Field</code>의 attribute이다. Torchtext는 하나의 <code class="highlighter-rouge">Field</code>가 하나의<code class="highlighter-rouge">Vocab</code>을 갖도록 만들어졌기 때문에(data가 갖는 게 아님!), 두 <code class="highlighter-rouge">Field</code>가 <code class="highlighter-rouge">Vocab</code>을 공유해야하는 경우엔 약간의 hack이 필요하다. 기계 번역의 경우엔 일반적으로 <code class="highlighter-rouge">Field</code>마다 <code class="highlighter-rouge">Vocab</code>이 필요하겠지만, src와 trg의 언어가 같은 대화 데이터 같은 경우엔 <code class="highlighter-rouge">Vocab</code>을 공유할 필요가 있다. 그럴 경우, <a href="https://github.com/pytorch/text/issues/232">임의의 <code class="highlighter-rouge">Field</code>가 <code class="highlighter-rouge">Vocab</code>을 갖도록 하고,  만들 때 src와 trg의 단어를 모두 사용하도록 한다.</a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SRC</span><span class="o">.</span><span class="n">build_vocab</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span> <span class="c"># Dataset</span>
<span class="n">TGT</span><span class="o">.</span><span class="n">build_vocab</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">tgt</span><span class="p">,</span> <span class="n">val</span><span class="o">.</span><span class="n">tgt</span><span class="p">)</span> <span class="c"># 'Example의 특정 Field 내용을 반환하는 iterator'</span>
<span class="c"># SRC.build_vocab(train.src, train.tgt, val.src, val.tgt) # possible</span>
</code></pre></div></div>

<p>무슨 데이터를 사용해서 <code class="highlighter-rouge">Vocab</code>을 만들지를 알려주기 위해 <code class="highlighter-rouge">.build_vocab()</code>의 인자로 <code class="highlighter-rouge">Dataset</code> 혹은 ‘<code class="highlighter-rouge">Example</code>의 특정 <code class="highlighter-rouge">Field</code>에 대한 iterator’를 넣어준다. 만약 pretrained vector를 다운로드 해서 쓸 거라면 여기서 vectors 인자를 넘겨야한다. 안 쓰는 경우엔 train, valid 데이터만 넣어줘서 test data 대한 정보 없이 vocab을 구성하는 것이 맞다. 하지만 pretrained vector을 쓸 거라면 train, valid, test 데이터 모두 넣어줘야한다(‘vocabulary expansion’). Train, valid에 등장하지 않았더라도 pretrained vector에 있는 단어라면 vocab에 포함시켜야한다는 것이다. 그러한 단어들은 어차피 train 때 추가적으로 학습되지 않고 기존 pretrained 값을 유지한다.</p>

<h2 id="torchtextdataiterator">torchtext.data.Iterator</h2>

<p><code class="highlighter-rouge">Iterator</code>는 <code class="highlighter-rouge">Example</code>을 모아 만든 <code class="highlighter-rouge">Batch</code>를 반복적으로 내뱉는 역할을 담당한다.  텍스트 데이터를 다룰 때 padding을 최소화하기 위해서 bucketing을 하는데, <code class="highlighter-rouge">BucketIterator</code>가 이를 담당한다. <code class="highlighter-rouge">Dataset</code>에 들어있는 <code class="highlighter-rouge">Example</code>은 list of string이다. <code class="highlighter-rouge">Iterator</code>는 string를 index로 바꿔서(numericalize), <code class="highlighter-rouge">torch.LongTensor</code>로 내뱉는다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_iter</span><span class="p">,</span> <span class="n">valid_iter</span><span class="p">,</span> <span class="n">test_iter</span> <span class="o">=</span> <span class="n">BucketIterator</span><span class="o">.</span><span class="n">splits</span><span class="p">((</span><span class="n">train</span><span class="p">,</span><span class="n">val</span><span class="p">,</span><span class="n">test</span><span class="p">),</span>
                                                     <span class="n">sort_key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">src</span><span class="p">),</span>
                                                     <span class="n">sort_within_batch</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                                     <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> 
                                                     <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cuda'</span><span class="p">),</span>
                                                     <span class="n">repeat</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="c"># sort_key는 Dataset안의 Example에 대해서</span>
<span class="c"># repeat=False 시 1 epoch 돌고 iter 끝남</span>
<span class="c"># sort_within_batch=True for pack_padded_sequence</span>
</code></pre></div></div>

<p><code class="highlighter-rouge">.splits()</code>의 인자로 shuffle 값을 주지 않으면 train iterator는 <code class="highlighter-rouge">shuffle=True</code>가 된다. 이는 train할 때 batch들이 random하게 뽑히는 걸 보장한다. <code class="highlighter-rouge">batch_size_fn</code>인자를 주면 <code class="highlighter-rouge">Batch</code>구성 기준을 <code class="highlighter-rouge">Example</code>개수에서 다른 것(e.g. token 개수)으로 바꿀 수 있다. 만약 GPU가 한 번에 몇 token까지 처리할 수 있는지를 알고있다면 cumstom <code class="highlighter-rouge">batch_size_fn</code>을 사용하는 게 GPU를 최대한으로 이용할 수 있는 방법이다.</p>

<p>모델 훈련 부분의 코드는 이렇게 구성할 수 있다. Iterator에서 repeat=False를 해줬기에 다음과 같이 epoch에 대한 for문을 사용할 수 있다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">EPOCH</span> <span class="o">=</span> <span class="mi">100</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCH</span><span class="p">):</span> <span class="c"># repeat=False 필요</span>
    <span class="k">for</span> <span class="n">train_batch</span> <span class="ow">in</span> <span class="n">train_iter</span><span class="p">:</span>
        <span class="n">src_batch</span><span class="p">,</span> <span class="n">tgt_batch</span> <span class="o">=</span> <span class="n">train_batch</span><span class="o">.</span><span class="n">src</span><span class="p">,</span> <span class="n">train_batch</span><span class="o">.</span><span class="n">tgt</span>
        <span class="k">pass</span> <span class="c"># train for one epoch</span>
    <span class="k">for</span> <span class="n">valid_batch</span> <span class="ow">in</span> <span class="n">valid_iter</span><span class="p">:</span>
        <span class="k">pass</span> <span class="c"># record valid performance</span>
</code></pre></div></div>

<h2 id="template">Template</h2>

<h2 id="questions">Questions</h2>

<ul>
  <li>is_target: Batch내에서 iterate할 때 target field에 해당하는 값이 나중에 나오도록</li>
  <li>ReversibleField 사용법?</li>
  <li>이미 있는 pretrained vector파일 불러와서 적용하는 방법은?</li>
  <li>vocab 저장</li>
</ul>

  
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
  </script>
  <script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
</div>

  <!-- Disqus -->

<div id="disqus_thread"></div>
<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */

var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://hwijeen-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


  <!--<div class="post-disqus">
      <section id="disqus_thread"></section>
      <div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables */

var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://hwijeen-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

  </div>-->


<div class="relatedPosts">

  <h3>Related Posts</h3>

  
  

  
  

  

  

    
    

    

    

  

    
    

    

    

  

    
    

    

    

  

    
    

    

    

  

    
    

    

    

  

    
    

    

    

  

    
    

    

    

  

    
    

    

    

  

    
    

    

    

  

    
    

    

    

  

    
    

    

    

  

    
    

    

    

  

    
    

    

    

  

    
    

    

    

  

    
    

    

    

  

    
    

    

    

  

    
    

    

    

  

    
    

    

    

  

    
    

    

    

  

    
    

    

    

  

    
    

    

    

  

</div>

<div class="recentPosts">

  <h3>Recent Posts</h3>

  
  

    
      
      <div class="post ml2">
        <a href="/2019-07-10/Data-to-Text-Generation-with-Content-Selection-and-Planning/" class="post-link">
          Data-to-Text Generation with Content Selection and Planning
          <small class="archive-list-post-date">10 Jul 2019</small>
        </a>
      </div>
      
    
      
      <div class="post ml2">
        <a href="/2019-07-10/Challenges-in-Data-to-Document-Generation/" class="post-link">
          Challenges in Data-to-Document Generation
          <small class="archive-list-post-date">10 Jul 2019</small>
        </a>
      </div>
      
    
      
      <div class="post ml2">
        <a href="/2019-05-10/Zsh-cheat-sheet/" class="post-link">
          Zsh 사용
          <small class="archive-list-post-date">10 May 2019</small>
        </a>
      </div>
      
    
      
      <div class="post ml2">
        <a href="/2019-02-20/A-Deep-Generative-Framework-for-Paraphrase-Generation/" class="post-link">
          A Deep Generative Framework for Paraphrase Genertion
          <small class="archive-list-post-date">20 Feb 2019</small>
        </a>
      </div>
      
    
      
      <div class="post ml2">
        <a href="/2019-02-19/Learning-Discourse-level-Diversity-for-Neural-Dialog-Models-Using-Conditional-Variational-Autoencoders/" class="post-link">
          Learning Discourse-level Diversity for Neural Dialog Models Using Conditional Variational Autoencoders
          <small class="archive-list-post-date">19 Feb 2019</small>
        </a>
      </div>
      
    
      
        

</div>


    <!-- Documents about icons are here: http://fontawesome.io/icons/ -->
<div class="footer">
  <hr />
  <div class="footer-link">
    
	
	
	
	

    

    
    <a href="https://github.com/hwijeen"><i class="fa fa-github" aria-hidden="true"></i></a>
    
	
	
	
	

    
	
	
	
	
	
	
	
	

    

    

    
    <a href="mailto:aurorall@naver.com"><i class="fa fa-envelope" aria-hidden="true"></i></a>
    

  </div>
  © 2018 Hwijeen Ahn. All rights reserved.
</div>

  </div>
</body>
</html>
